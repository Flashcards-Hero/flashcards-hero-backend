1 Review questions [Introduction, main memory (Chapter 9), virtual memory (Chapter 10)] CPSC 5042 Spring 2023 1- Draw Von Neumann’s architecture of a computer. 2- What are the five main categories of modern computer systems? Answer : Personal Mobile Device (PMD) Desktop Computing Servers Clusters / Warehouse Scale Computers Embedded Computers 3- What is the primary task of an “operating system ?” Answer1 : A program that acts as an intermediary between a user of a computer and the computer hardware. Or Answer2 : OS is a resource allocator, which manages all resources, decides between conflicting requests for efficient and fair resource use, and controls programs within allocated space. 4- What are the two main characteristics of an OS? Answer : Efficiency and convenience. Efficiency means that the OS can manage multiple processes and allocate memory to these processes fairly and efficiently. For example, if one process is trying to hug a large number of frames, the other processes should not be denied active frames. If a process is not using its frame or CPU assets, that process should be deactivated. In servers, efficiency is of main importance. Convenience is a factor that a system user expects from the OS. Allowing a user to access programs and applications easily is an example. In mobile devices, convenience is a major factor. 2 5- Which of the following tasks would require OS support? Questions Explanation of the answers. 1) Input a character from the keyboard. Decently Not necessarily All devices require OS support to conduct complex interactions transparently with the user. 2) Invoke a high-level matrix manipulation operation. Decently Not necessarily The compiler can translate high-level operations on complex data structures into the corresponding machine instructions, which then execute without any help from the OS. 3) Allocate n bytes of memory for a new data structure. Most likely Not necessarily The OS must manage the partitioning of memory to protect concurrent users from one another and optimize memory usage. Some of the dynamic memory could be pre-allocated, but OS intervention is generally required. 4) Load a program into memory. Decently Not necessarily The OS must manage the partitioning of memory to protect concurrent users from one another and optimize the use of memory. 5) Change the layout of a document. Decently Not necessarily A text editor manipulates a document. If the document is in memory, the change is made without requiring any OS services. 6) Call a shared library function. Most likely Not necessarily Due to many possible library functions, the OS may postpone the loading and linking of a function until the function is needed. 7) Call a function defined within the current program. Decently Not necessarily The compiler and the linker combine functions into a single module, where the call results in a branch instruction within the program. No OS involvement is needed. 8) Exit current program. Decently Not necessarily When a program terminates, the OS must free up memory and other resources used by the program. 9) Sleep for n seconds. Decently Not necessarily The OS must select and run another program while the requesting program is blocked to avoid wasting CPU time and other resources. 6- Explain the role of the OS as the resource manager . Answer : One of the main tasks of an OS is to optimize the use of all computational resources to ensure good overall performance while satisfying the requirements of specific applications, including guaranteeing acceptable response times for interactive processes, meeting deadlines of time-critical tasks, and allowing safe communication among different tasks. A program typically alternates between phases of input, computation, and output. Consequently, the CPU is underutilized during the I/O phases, while the I/O devices are idle during the compute phase. The overall performance of all applications can be improved by using concurrency . The OS tries to keep the CPU, main memory, and all storage and I/O devices busy at all times by overlapping independent operations whenever possible. 3 7- What is “ multiprogramming ?” Answer : Multiprogramming is a technique that keeps several programs active in the main memory and switches execution among the different programs to maximize the use of the CPU and other resources. Whenever a program enters an I/O- bound phase where little CPU time is needed, other programs can resume and utilize the CPU in the meantime. Similarly, whenever a device completes an operation, the OS activates computations that can utilize the now available device. 8- What is time-sharing? Answer : Time-sharing (multitasking) is an extension of multiprogramming where the CPU is switched periodically among all active computations to guarantee acceptable response times to each user. Time-sharing employs the concept of virtualization by creating the illusion of having a separate virtual CPU for each computation. 9- Assume we have one CPU and two I/O devices. We want to execute two programs, A and B. What are each of the following three situations? Answer : Situation 1 is a sequential system. First, program A is executed, and then program B. Situation 2 is a multiprogramming case. Finally, situation 3 is time-sharing, where the switching between programs A and B is done very quickly, and we are showing them as running in parallel. 10- Answer the following questions about multiprogramming: 1) Multiprogramming generally improves CPU utilization and throughput. (True or False?) Answer : True: Multiprogramming overlaps phases of computation and I/O from different computations to better utilize the CPU and other resources, which improves overall performance. 2) The main objective of time-sharing is to improve resource utilization. (True or False?) Answer : False: Resource utilization is improved by multiprogramming, which overlaps CPU- bound and I/O-bound computations. On the other hand, Time-sharing only switches the CPU among different computations to create the illusion of simultaneous execution, which generally does not improve resource utilization beyond simple multiprogramming. 3) Multiprogramming and time-sharing are not used together. (True or False?) Answer : True: Time-sharing requires multiprogramming since multiple computations must be active at the same time. 4 11- In a hypothetical system, the average computation spends 50% of the total time using the CPU and the remaining 50% waiting for I/O. For such a system, answer the following questions. 1) To achieve the best CPU utilization, _____ computations should run simultaneously. a) 2 b) more than 2 c) all available processes Explanation: Using more than two computations increases CPU utilization but, at the same time, uses more memory and other resources. A careful balance must be found to minimize overhead while still increasing overall performance. 2) The use of time-sharing will _____. a) speed up all computations b) guarantee a reasonable response to each computation. c) improve resource utilization Explanation: No computation can monopolize the CPU indefinitely. 12- Processes p1 and p2 share a single CPU and two independent I/O devices. Each process executes a compute-bound phase of 10 time units followed by an I/O- bound phase of 10 units. Answer the following questions. 1) Without multiprogramming, the total execution time of both processes is ____ time units. a) 20 b) 30 c) 40 Explanation : The processes execute all phases sequentially: (10 + 10) + (10 + 10) = 40 2) With multiprogramming, the total execution time of both processes is ____ time units. a) 20 b) 30 c) 40 Explanation : The compute-phase of the second process can start immediately following the compute phase of the first process and thus overlap with the I/O phase of the first process. 3) If p1 and p2 use time-sharing and the length of the time interval allocated to each process is negligible compared to the 10 time-units of execution, then the total execution time of both processes is ____ time units. a) 20 b) 30 c) 40 Explanation : The CPU keeps switching between the two processes, but each takes ten time units. (20 time-units). The I/O phases start almost simultaneously and execute in parallel for approximately 10 units. 5 13- Processes p1 and p2 execute on a system with a single CPU and two identical I/O devices. Each process executes a compute-bound phase followed by an I/O- bound phase. The system uses multiprogramming without time-sharing. The following table shows the lengths of each phase. Compute I/O p1 40 50 p2 30 70 p1 starts first at time 0. A process has to finish its computation before it can begin its I/O. Q1) Without multiprogramming, the computation terminates at time ____A___ . Q2) With multiprogramming, the computation terminates at time _____B___. Answer : A = 40 + 50 + 30 + 70 = 190 B = 40 + 30 on the CPU then p2 spends 70 on the I/O = 140 14- What is the OS kernel? Answer : The kernel of an OS is the minimal set of functions necessary to manage the system resources safely and efficiently. The kernel typically provides essential services for memory and device management , creating and managing computations , and communication among the different concurrent activities within the system. 15- What are privileged instructions ? Answer : The instruction set provided by the CPU is divided into two sets of privileged and non-privileged to deal with security issues. A privileged instruction performs critical operations that access I/O devices and the CPU’s status and control registers. Thus only the OS kernel is allowed to execute privileged instructions . 16- What are the two modes that the CPU operates? Answer : The CPU operates in two different modes, indicated by a particular mode bit, to guarantee that no programs outside the trusted kernel can use privileged instructions. Kernel mode is the CPU state where both privileged and non-privileged instructions may be used. User mode is the CPU state where only non-privileged instructions may be used. Any attempt to execute a privileged instruction in user mode automatically transfers control to the kernel. 6 17- Answer the following questions about the OS kernel and privileged instructions. 1) Kernel functions may be invoked by _____.  only the system call libraries  only system calls or general libraries  any program Explanation : Any program can issue a supervisor call to request service directly from the kernel. 2) Privileged instructions may be executed by _____.  only the kernel  the kernel and system call libraries  any program Explanation : No program outside the kernel can use privileged instructions. 3) An application that needs to access an I/O device could not be written without _____.  kernel and library functions  kernel functions Explanation : Privileged instructions are needed to access an I/O device, which only the kernel can execute. 4) The kernel can execute _____ instructions.  only privileged  both privileged and non-privileged Explanation : The kernel always executes in kernel mode, which allows the use of privileged instruction 18- What do interrupts and traps have in common? What are the differences between the two concepts?. Answer : Traps and interrupts both suspend the execution of the current instruction sequence and temporarily divert control to a dedicated area within the OS kernel. An external event causes an interrupt. Ex: The completion of an I/O operation or a timeout signal from a clock. Interrupts are asynchronous to the current execution in that the interruption may occur unpredictably between any two instructions. A trap is a particular case of an interrupt caused by an event internal to the current execution. Ex: The execution of a privileged instruction or an arithmetic overflow. Traps are synchronous to the current execution in that the currently executing instruction causes the interruption. The interruption can be unintentional, as in the case of an error, or intentional, as in the case of a supervisor call. 19- What is a process, and what is a process’s PCB? Answer : A process is an instance of a program being executed by an OS. For example, when a user opens a new application like a web browser or text editor, the OS creates a new process. The OS itself is organized as a collection of processes. The OS keeps track of each process using a process control block (PCB). PCB is a data structure that holds information for a process, including the current instruction address, the execution stack, the set of resources used by the process, and the program being executed. 20- What is the content of the PCB of a process? Answer : PCB contains a list of registers of the process, program counter, memory management information, process id, process state, and a list of files that are opened by the process. 7 21- Answer the following four questions about PCBs. Questions Explanation: 1) An OS uses a PCB to represent a process. True False The OS implements every process as a data structure called PCB, the process control block. 2) The PCB is created by the process when execution starts. True False The PCB is a data structure created and maintained only by the OS, not the process itself. 3) The PCB becomes part of the program being executed by a process. True False The PCB is an independent data structure managed by the OS that is destroyed when the process terminates. The program remains unchanged. 4) Two processes can execute the same program. True False A program can be executed multiple times simultaneously, each instance being a process. Therefore, each PCB has a separate program counter to track each process’s execution location in the program. 22- Consider the following state diagram, which shows three possible states a process could possess. Then, explain how the process’s state is changed. Answer : A newly created process starts in the ready state. When the OS selects the process for execution, it goes to the running state. When the OS interrupts the process, for example, to let some other processes use the CPU, its state changes to ready . When a process requests a currently unavailable resource, such as a file already opened by another user or some input data, the process’s state changes to “ blocked .” When some other process releases the resource or generates the data needed by the blocked process, the OS moves the blocked process to ready . 8 23- Answer the following questions regarding the state of a process. The transition (ready - > running) of a process p is caused by _____. a) the OS b) the process p itself c) some other process Only the OS can decide when a process should continue to run. The transition (running - > blocked) of a process p is caused by _____. a) the OS b) the process p itself c) some other process p causes the transfer when requesting a currently unavailable resource. The transition (running -> ready) of a process p is caused by _____. a) the OS b) the process p itself c) some other process The OS may wish to let another process use the CPU. The transition (blocked -> ready) of a process p is caused by _____. a) the OS b) the process p itself c) some other process p is waiting for a resource held by or generated by some other process q. The release of the resource or data by q causes the transition of p back to ready. 24- The networks are categorized into four groups for networked distributed computing in terms of the distance between members. What are these four types of networks? Answer : LAN, WAN, MAN, PAN 25- In terms of the role of connected network members, computing environments are divided into two types. What are these two types of networks? Answer : 1) client-server, 2) peer-to-peer. 26- What is the difference between “emulation” and “virtualization ?” Answer : A. Emulation is used when the source CPU type (physically present) differs from the target CPU type (the CPU for which a program is compiled for). For example, Apple desktops switched from IBM CPU to Intel CPU, and old software used Rosetta to run on emulated IBM CPU. B. Virtualization allows a guest OS to run as an application on a host OS. 9 27- What is the difference between “ full virtualization ” and “ para- virtualization ?” Answer : In full virtualization, the guest is an original OS and wants to manage the memory, perform protection, etc. In para-virtualization, guest OS is designed to run as a guest in a virtual environment, is aware of other operating systems, and knows its limitations. Para-virtualization requires the guest operating system to be modified to use the hypervisor’s APIs, making it more efficient than full virtualization in terms of CPU utilization and memory access. Para-virtualization is best suited for situations where a high level of performance is required, such as in high- performance computing or data-intensive workloads. 28- What are the three types of services that cloud environments offer? Answer: SaaS (software as a service), PaaS (platform as a service), and IaaS (infrastructure as a service). 29- What are the three types of “cloud computing?” Answer: Private, public, hybrid 30- What are the three advantages of a “multiprocessor system” over a single processor? Answer: 1- Increased throughput, 2- Lower cost than using a collection of single processors, 3- Reliability is higher, and the system is more fault-tolerant. 31- What is the difference between “symmetric” and “asymmetric” multiprocessors ? Answer : Asymmetric multiprocessor is a CPU scheduling method in which all scheduling decisions, I/O processing, and other system activities are handled by a single processor — the master server. The other processors execute only user code. This is a simple method because only one core 10 accesses the system data structures, reducing the need for data sharing. The downfall of this approach is that the master server becomes a potential bottleneck where overall system performance may be reduced. Symmetric multiprocessor (SMT) is the standard approach for supporting multiprocessors where each processor is self-scheduling. 32- What are the five activities of “process management?” Answer : 1-Creating and deleting both user and system processes 2-Suspending and resuming processes 3-Providing mechanisms for process synchronization 4-Providing mechanisms for process communication 5-Providing mechanisms for deadlock handling 33- What is the difference between “program” and “process”? Answer: A program is a collection of instructions and is a passive entity. A process is a program in execution and is an active entity. 34- What is a memory unit exposed to? Answer : 1- A stream of addresses + read requests 2- A stream of addresses + data and write requests 35- For a cache system, how long does one memory access take? Answer : It takes many CPU cycles. AMAT= cache-hit-time+ miss-rate*miss-penalty 36- How long does one register access take? Answer : It takes one clock cycle (or less) 37- What do we mean by “throughput of memory”? Answer : Number of bytes accessed in a time unit (Bytes/sec) 38- What does “memory management” mean? Answer : A system that determines what is in memory and when . It is a system that optimizes the CPU’s utilization and the overall computer’s response to users. (this question says what MM has to do, but we don’t say how it will be done) 39- What does memory management do? Answer : This is how MM should implement its goal: It keeps track of which parts of the memory are currently being used. It means there is, for example, a table showing which frames are occupied by what pages. Next, it decides which processes (or parts thereof) and data to move into and out of the memory. It means that the tale has a column for the process IDs showing what pages each process owns. Finally, it allocates and 11 deallocates the memory space as needed. The table should be updated as the processes come in or go out. 40- What is meant by the performance difference (gap) between DRAM and CPU? Answer: The throughput of DRAM is much lower than what the CPU requires. 41- What is “memory hierarchy”? Answer: Creating a pyramid with slow, cheap, and large memory at the bottom and placing fast, expensive, and small memories at the top. 42- What is the “locality of reference”? Answer: When a reference is made to memory, the same location, or locations near that, will be referenced soon. 43- How could we overcome the performance difference? Answer: By using memory hierarchy. 44- What is the effect of a “low” locality of reference? Answer: Low locality causes a high miss rate, forcing memory management to refer to slower parts of the hierarchy. 45- Suppose reading one word from the main memory takes 50 clocks, and reading one block of words from memory would take 100 clocks. Also, assume that reading one word from the cache would take 2 clock cycles. What should be the maximum cache “miss rate” for this memory system to be worth having the cache rather than directly accessing the main memory ? Answer: 50> 2 +miss_rate*100. miss_rate should be less than 0.48 46- What are the primary and secondary memory layers? Answer: 47- What are the four categories of memories in terms of “access type”? Answer: RAM, SAM, DASD, CAM. Nowadays, SAM (sequential access memory) is not used anymore. RAM (Random access memory) is the method of accessing SSDs and main memory. DASD is the method of accessing hard disks, a 12 combination of SAM and RAM. Finally, CAM (Content addressable memory or Associative Memory) is widely used. For example, CAM is used in TLBs, cache structures, routers to lookup destination IPs, image search to lookup image descriptions, etc. 48- What is the “inclusion principle” in the memory hierarchy? Answer: The content of layer 𝑖𝑖 of the hierarchy has to exist in layer 𝑖𝑖 + 1 . 49- What are the four policies or questions in managing a memory hierarchy? Answer: 1- placement policy, 2- identification policy, 3- replacement policy, 4- update policy. 50- What is “mapping” in the context of memory management ? Answer: conversion of virtual addresses to physical addresses is called mapping. 51- What is “address binding”? Answer: As a general definition, binding means mapping from one address space to another. Traditionally, binding is categorized into compile-time-binding, load-time-binding, and execution-time- binding. 52- Explain why load-time binding is not “dynamically relocatable” and why execution-time binding is dynamically relocatable . Answer : Load time binding : The compiler translates symbolic addresses to relative (relocatable) addresses. The loader translates these to absolute addresses. If it is not known at compile time where the process will reside in memory, then the compiler must generate relocatable code. This is done once, and swapping cannot be performed, which makes the method static. Execution time binding : If the process can be moved during its execution from one memory segment to another, then binding must be delayed until run time. The absolute addresses are generated by hardware. Most general-purpose OSs use this method (Dynamic). Static-binding means locations are determined before execution. Dynamic- binding means locations are determined during execution. 53- What are “logical” and “physical” addresses ? Answer : Logical address – addresses generated by a program and sent to the CPU; also referred to as virtual address Physical addresses are addresses seen by the memory unit assigned to a program depending on where the program resides in the main memory. 54- What is the job of the memory management unit (MMU)? Answer : The run-time mapping from virtual to physical addresses is performed by hardware called the memory-management unit (MMU). 13 55- What is “dynamic relocation”? Answer : Dynamic relocation is relocating data or codes currently in the computer’s memory to other parts of the computer, creating more efficient memory storage while a program is still active. 56- What are the minimum hardware requirements of an MMU for a dynamic relocation? Answer: a relocation register. 57- Which type of program benefits most from dynamic relocation ? Answer: A significant portion of the code is used for rare cases in some programs, and only a small piece of the code is frequently used. For such applications, dynamic relocation can be used efficiently. Such applications are known as 20- 80, which means that 20% of the code is used 80% of the time. 58- What is a “stub”? Answer : Stub is used for dynamic linking, where linking is postponed until execution time. A stub is a small piece of code used to locate the appropriate memory-resident library routine. Stub replaces itself with the address of the library routine and executes the routine. 59- What is the “Contiguous allocation” of memory? Answer : Contiguous allocation means allocating a contiguous region of the main memory to a program. 60- Why is segmentation considered “Contiguous” and paging considered “non-Contiguous”? Answer : Segmentation allocates one piece of memory, called a segment, to one program. Different parts of the memory, called pages, could contain a part of a program in paging. These pages could be non- contiguous. 61- What are the elements of the two-tuple that a segment is referred to? Answer : segment number and offset. 62- What are the minimum hardware requirements in a multiprogramming system to ensure that each program only accesses its memory space? Draw a simple block diagram for this protection system . Answer : A base and a limit register are needed. 14 63- a) How could we define efficiency in a “variable partitioning” memory system? b) What happens when a new process arrives? c) What happens when the process exists? d) What kind of information does the OS maintain in such a system? Answer: a) The percentage of occupied memory when there is no room for a new process is the efficiency—the higher this percentage, the smaller the useless fragments. b) When a process arrives, it is allocated memory from a hole large enough to accommodate it. c) The exiting process frees its partition. Then, adjacent accessible partitions are combined. d) OS maintains information about allocated partitions, and free partitions (holes) 64- What strategies for “placement policy” in a “dynamic allocation” memory system are possible ? Answer : First fit, best fit, worst fit. 65- What are the two types of memory fragmentation? Answer : internal fragmentation, external fragmentation. 66- Which type of fragmentation occurs in the Contiguous allocation system? Answer : external fragmentation occurs between segments. 67- True or false?: The 50 - percent rule states that 50 % of memory is lost to external fragmentation when the first-fit policy is used. Explain your answer. Answer : False. The 50% rule means that 50% of the occupied space is useless fragments. Hence, if segments occupy N bytes, then N/2 bytes are fragments, which is 1/3 of the total memory space. 15 68- What is a solution for memory fragmentation in contiguous allocation? What are the prerequisites of such a remedy, and what are the problems ? Answer : compaction is the solution. It requires that the code and data be relocatable. 69- How does the “paging” system partition a program? Does it have to bring the whole program into the memory? Answer : Page size is a power of 2. In paging, only one page of a program or data has to bring into the memory. Other parts of the code or data are brought into the memory as needed. 70- What is the difference between a “frame” and a “page”? Answer : The frame and page are of the same size. A frame is referred to as a physical piece of memory, and a page is referred to as the virtual address space. 71- What is the job of a “page table”? Answer : It contains a translation (mapping) of virtual to physical addresses. 72- Assume that the logical address is 24 bits and the physical memory is 1MB. Also, assume that each page or frame is 4KB. a) Show how the logical and physical addresses are partitioned. b) What is the size of the page table? c) Assume the logical address is ABCDEF, the content of the page table in line DEF is AB, and in line ABC is F5. Where in the physical memory is this logical address mapped ? Answer : 16 a) b) Page table has 2^12 lines. c) Virtual address ABCDEF is at address F5DEF. 17 73- Imagine that we have fixed page sizes of size 2048 bytes. Also, imagine that the process size is P. Write a C code that, for 10000 times, randomly generates an integer P between 1 and 20000. Then for each value of P, determine the amount of internal fragmentation and calculate the mean value of that. Copy/paste your code into your solution file. Also, report the average value of internal fragmentation. Answer : #include <stdio.h> #include <stdlib.h> #include <time.h> int main () { int c , p , frag , frag_avg ; int frag_sum = 0 ; int page = 2048 ; printf ( \"10000 random numbers in [1,30000]\\n\" ); //Use current time as seed for random generator srand ( time ( 0 )); for ( c = 1 ; c <= 10000 ; c ++) { p = rand () % 30000 + 1 ; if ( p < page ){ frag = page - p ;} else { frag = p % page ;} frag_sum = frag_sum + frag ; frag = 0 ; } frag_avg = frag_sum / 10000 ; printf ( \"average fragmentation is %d\\n\" , frag_avg ); return 0 ; } 74- Accessing the page table may have considerable delays. What is a solution to reduce the average delay of the page address mapping? Answer : Use of TLB. 18 75- Suppose the logical address is 32 bits. The physical memory is 16MB. Pages are 4KB. There is a TLB with 64 lines of associative memory with an access time of 0.5 cycles. The access time of the page table is one cycle. The miss rate of TLB is ten percent. a) How big is the page table? b) What is the average access time of this system? c) Now consider the content of the page table and TLB as shown below. Suppose logical address D00EF123 is issued, which cannot be found in the TLB. Where in the physical memory is this address mapped? Where will the logical address 12345F05 be mapped in the main memory? d) Convert logical address FEDC05F2 to a physical address. Answer : a) The page table has 2^20 lines. (32bits-12bits)= bits for virtual page # b) EAT= 0.9*0.5+ 0.1*1=0.55 cycles c) D000EF is the page number that is mapped at frame number 56F. Hence, the physical address is 56F123 . The logical address 12345F05 is found in the TLB and the page table. We take the TLB content, which tells us that the physical address is 567F05 . d) FEDC05F2 is mapped to F565F2 . 19 76- What is the purpose of using “valid bit” in the page memory table? Answer : This bit is just for protection purposes. The “valid” bit indicates that the associated page is in the process’s logical address space and is, thus, a legal page. The page is not in the process’s logical address space when the bit is invalid. The use of the valid-invalid bit traps illegal addresses. The operating system sets this bit for each page to allow or disallow access to the page. 77- What is a “reentrant” page? Usually, reentrant pages belong to some specific processes. Name two examples of such processes. Answer : the Reentrant code is non-self-modifying: it never changes during execution. Thus, two or more processes can execute the same code simultaneously. Each process has its copy of registers and data storage to hold the data for its execution. The data for two different processes will, of course, be different. The reentrant page is a read-only copy of code shared among processes. Examples are text editors , compilers , C libraries , and Windows systems. 78- Name three strategies that are used to reduce the size of page tables when the logical address is large. Answer : Hierarchical Paging, Hashed Page Tables, Inverted Page Tables 79- Suppose the logical address is 32 bits and the page offset is 12 bits. Show an example of a hierarchical page address. Answer : 80- We have 32-bit virtual addresses and 24-bit physical addresses. 20 Assume that we have 4KB pages. Based on the following diagram’s content, where is the virtual address ABCDEF00 mapped? Where do we map F00BC000? Where do we map 12356FFF? Answer : ABCDEF00 is mapped to 567F00. Virtual address F00BC000 is mapped to 345000. Logical address 12356FFF is not yet mapped to a physical address. 81- Why is a hierarchical page addressing difficult for 64-bit logical addressing? What are the two alternative methods? Answer : Even a three- level page table requires a 2^32 line third-level table. If we use more page table layers, for example, eight layers, then going through all layers to find the page’s address would be prohibitively long. Alternative approaches are using hash tables and TLBs . 82- Explain the following diagram. What are p, q, s, r, and d? Suppose the 64- bit logical address of F1234567890ABCDE is mapped into the physical address of 4FFCDE. What are the values of p, d, and r? Also, give an example of the value of q. 21 Answer : we see that pages are 4KB since the low significant 12 bits of the physical and logical addresses are the same. P is the page number which is 52 bits, and the first 13 Hex digits of the address. r is 4FF, and d is CDE. q is another 52-bit page number that is hashed into the same place as p is hashed to. Since we don’t know the hash function, we can throw in any 52-bit number as q. For example, CADF13571234F is q. 83- a) What is an “inverted page table?” b) How can we limit the search process? Answer : a) The page table is as big as the number of physical pages. This method makes the page table size much smaller than using a table that has 2^(number of virtual pages). b) hashing could be used to limit the search. For example, the virtual page number is hashed in three different methods to restrict the search to only three entries of the inverted table. 84- The 64-bit Sparc Solaris uses two hash tables. What are these two tables? What is “page walk” in the memory mapping process of this system?. Answer : two hash tables are used. One table is used for the user codes, and one table for the OS. Also, a TLB is used for fast search. Page walk: If the address is not in the TLB, the system “walks back” and searches the hash tables. 85- Some operating systems occasionally deactivate “swapping.” What is the purpose, and what are the occasions? Answer : swapping requires the transfer of data and code from the main memory to the backing store. The data transfer is time-consuming. In UNIX, swapping is disabled until the number of allocated pages becomes higher than a threshold. 86- Suppose that a process takes 200MB of the main memory. This process has to be swapped by sending it to the backing memory and bringing a new 22 process, of the same size, into the main memory. The transfer rate is 150MB/sec. How long will this context switch take? Answer : 200 𝑀𝑀𝑀𝑀 + 200 𝑀𝑀𝑀𝑀 = 400 𝑀𝑀𝑀𝑀 ⇒ 400𝑀𝑀𝑀𝑀 150𝑀𝑀𝑀𝑀 / 𝑠𝑠𝑠𝑠𝑠𝑠 = 2.67 𝑠𝑠𝑠𝑠𝑠𝑠 87- What is a “pending I/O” during process swapping? Explain “double buffering” that is used to remedy pending I/O. Answer : Sometimes, a process has to be swapped into the backing store, and that process may have been transferring data from I/O. The swapped-out process would lose the data. OS could use its memory space to buffer the I/O data, and when the process is brought back into the main memory, OS should deliver the buffer data to the process. The data is moved twice, which is called double buffering. 88- What is the maximum size of a segment in an IA-32 system? What are the differences between LDT and GDT? The logical addresses in IA-32 systems consist of two parts. What are these two parts called, and what are their purposes? Answer : Addresses in IA-32 systems consist of a selector and an offset. A selector is a 16-bit number consisting of s (13 bits), g (1 bit), p (2 bits). The s part designates the segment number, and g indicates whether the segment is in the global descriptor table (GDT) or the local descriptor table (LDT). Also, the 2 bits p is used for protection. An offset is a 32-bit number specifying the location of the byte within the segment in question. An offset of 32 bits means each segment could be as large as 4GB. 89- The following diagram shows the addressing system of the IA-32. What is the difference between addressing a 4KB page and a 4MB page? 23 Answer : If the virtual address is 32 bits, then the physical address is usually less than 32 bits, for example, 28 bits. The high 10 bits of the virtual address are used to find a line in the page directory. A bit in the content of the page directory line indicates if the page size is 4MB or 4KB. For 4MB pages, the page directory provides a 28 -bit start address, and we add our 4MB page offset of 22 bits to that. For 4KB pages, the page director offers a 28-bit address that points to the start of a page table. The page table has 2^10 lines, and using the page table part of the virtual address, we refer to the appropriate line of the table. The content of the page table is a 28-bit physical address which we add the 12-bit offset to it to get the physical address of the line of the 4KB page. 24 90- The addressing method in the ARM architecture is shown below. Explain how this architecture works for 4KB, 16KB, 1MB, and 16MB pages. Answer : If the virtual page table is 32 bits, then the physical address is smaller, and it is, for example, 28 bits. The outer page table entries consist of two bits that indicate the page size. For example, “00” means the page size is 4KB, “01” means 16KB, “10” means 1MB, and “11” means that the referenced page is 16MB. Besides these two bits, the content of the outer page table has 28 bits, which refer to either the inner page table or a 1MB or 16MB page. Hence, the offset part could be 12 bits, 14 bits, 20 bits, or 24 bits. 25 91- What are the advantages of using Virtual memory ? Answer : a) Only part of the program needs to be in memory for execution, b) Logical address space can be much larger than physical space, c) Several processes can share address spaces, d) More efficient utilization of physical memory, e) More programs can run concurrently, f) Less I/O needed to load processes 92- How could we implement Virtual memory? Answer : Demand paging and demand segmentation. 93- What is the usual practice in the utilization of virtual address space? Answer : A program consists of a fixed-size code and different data types. The stack starts at the highest virtual address, and the code begins at address zero. On top of the code are data, and on top of the data, the heap of linked variables is placed. 94- What is a “lazy swapper”? Answer : It starts swapping segments only when the swap is needed to free space in the physical memory. 95- What is a “pager”? Answer : It performs the swapping operation on “pages” rather than segments. 96- How is the “valid-invalid (VI)” bit used in a page table ? Answer : if there were no such a bit, then the table’s initial content may be considered valid frame numbers even if all the table entries were zero. Hence, initially, all of the “VI” bits are zero. Initially, the first demand page causes a “page fault” because the VI bit is zero. After the page is read, the bit becomes valid (one). 97- What are the contents of the entries on the page table below? 26 Answer : Line 0 of PT has 4, line 2 has 6, and line 5 has 9. Valid bits of these lines are 1. The rest of the page table is empty (valid bits are zero.) 98- What does the following diagram show? Write down steps 1 to 6 . 27 Answer : a) CPU is referencing a page that is not in the physical memory, and it has an “invalid” bit in the page table b) A trap (interrupt) occurs, and OS takes over the execution process c) OS finds the demanded page in the hard disk d) OS brings the demanded page into the physical memory e) OS updates the page table’s frame number and valid bit. f) The interrupted instruction of the process takes back control and restarts execution. 99- What is the “zero-fill-on-demand” strategy? Answer : OS adds a frame to the list of “free-frame-list” by zeroing the content of a frame. 100- Does the zero-fill-on-demand strategy increase the efficiency of demand paging? Answer : No. It adds an overhead. It doesn’t help identify free frames because checking the zero content of a frame is a lengthy process. Testing the valid bit of a frame is much faster than seeing if the frame’s content is zero. Hence, the only reason for zeroing the content is for security purposes. 101- For a demand paging system, assume that the page fault rate is 𝒑𝒑 . What is Effective Access Time (EAT) for such a system? Answer : Average access time is: (probability of finding the page in a frame × access time of the frame) + (probability of page fault × delay time to get the page from the disk). The probability of page fault is 𝑝𝑝 , and the probability of finding the page in a frame of the main memory is 1 − 𝑝𝑝 . The delay time to get the page from disk includes (page fault overhead + swap page out + swap page in). Hence, 𝐸𝐸𝐸𝐸𝐸𝐸 = (1 – 𝑝𝑝 ) × ( 𝑚𝑚𝑚𝑚 𝑖𝑖 𝑚𝑚 𝑚𝑚 𝑠𝑠 𝑚𝑚𝑚𝑚𝑚𝑚𝑚𝑚 𝑚𝑚𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑡𝑡 𝑖𝑖𝑚𝑚𝑠𝑠 ) + 𝑝𝑝 ( 𝑝𝑝 𝑚𝑚 𝑝𝑝 𝑠𝑠 𝑓𝑓 𝑚𝑚 𝑓𝑓𝑓𝑓 𝑡𝑡 𝑚𝑚 𝑜𝑜 𝑠𝑠𝑚𝑚 ℎ 𝑠𝑠𝑚𝑚 𝑒𝑒 + 𝑠𝑠𝑠𝑠 𝑚𝑚𝑝𝑝 𝑝𝑝 𝑚𝑚 𝑝𝑝 𝑠𝑠 𝑚𝑚𝑓𝑓𝑡𝑡 + 𝑠𝑠𝑠𝑠 𝑚𝑚𝑝𝑝 𝑝𝑝 𝑚𝑚 𝑝𝑝 𝑠𝑠 𝑖𝑖 𝑚𝑚 ) 102- For a demand paging system, assume the following. The main memory access time is 300 ns, and the access time to the hard disk is 11 ms (including all the overheads and swap in and out time.) We want the effective access time for such a system to be only 20% larger than the main memory access time. What should be the maximum page fault rate ? Answer : We use the answer to question 80: 𝐸𝐸𝐸𝐸𝐸𝐸 = (1 – 𝑝𝑝 ) × ( 𝑚𝑚𝑚𝑚 𝑖𝑖 𝑚𝑚 𝑚𝑚 𝑠𝑠 𝑚𝑚𝑚𝑚𝑚𝑚𝑚𝑚 𝑚𝑚𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑡𝑡 𝑖𝑖𝑚𝑚𝑠𝑠 ) + 𝑝𝑝 ( 𝑚𝑚𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑡𝑡 𝑖𝑖𝑚𝑚𝑠𝑠 𝑡𝑡 𝑚𝑚 ℎ 𝑚𝑚𝑚𝑚𝑒𝑒 𝑒𝑒𝑖𝑖𝑠𝑠 𝑑𝑑 ) 28 𝐸𝐸𝐸𝐸𝐸𝐸 = (1 − 𝑝𝑝 )300 𝑚𝑚𝑠𝑠 + 𝑝𝑝 (11 𝑚𝑚 𝑠𝑠 ) = 300 𝑚𝑚𝑠𝑠 – 𝑝𝑝 × 300 𝑚𝑚𝑠𝑠 + 𝑝𝑝 × 11000000 𝑚𝑚𝑠𝑠 We want EAT to be 20% higher than 300ns. Therefore, we want EAT to be 300ns +20% (300ns) = 360ns= 120% of 300ns. 𝐸𝐸𝐸𝐸𝐸𝐸 = (1 − 𝑝𝑝 )300 𝑚𝑚𝑠𝑠 + 𝑝𝑝 (11 𝑚𝑚 𝑠𝑠 ) = 300 𝑚𝑚𝑠𝑠 – 𝑝𝑝 × 300 𝑚𝑚𝑠𝑠 + 𝑝𝑝 × 11000000 𝑚𝑚𝑠𝑠 = 360ns So, if EAT is supposed to be 360, what is the maximum value of page fault probability (what is the value of p)? 360 𝑚𝑚𝑠𝑠 = 300 𝑚𝑚𝑠𝑠 + (11000000 𝑚𝑚𝑠𝑠 − 300 𝑚𝑚𝑠𝑠 ) 𝑝𝑝 60 𝑚𝑚𝑠𝑠 = (11000000 𝑚𝑚𝑠𝑠 − 300 𝑚𝑚𝑠𝑠 ) 𝑝𝑝 ⇒ 𝑝𝑝 = 0.0000054 If you want the average access time to the memory to be only 20% more than the access time to the main memory, the page fault frequency should be only 1 in 185185. 𝑝𝑝 = 1 185185 = 0.0000054 . Page table Main memory Hard disk Delay of page table is very small compared to delays of the main memory or the hard disk . S o we ignore this delay . P percent of times page faults occur and refer to hard disk ( 1 - P ) percent of the times access the page from the main memory Effective access time = ( 1 - P ) ( main _ memory _ access _ time ) + ( P ) ( hard _ disk _ access _ time ) Cache Main Memory Always refer to cache . It takes ( 1 ) × t hit m percent of the time there is a miss and we have to refer to the main memory . m ×miss _ penalty Average memory access time = t hit + m ×miss _ penalty 29 103- What is “copy-on-write?” Answer : Occasionally, two identical processes are created. Each one should have its own memory space. But OS places only one set of pages for both processes to use. If process1 writes into the shared page A, then page A is copied for process1. As a result, process2 will have the original copy of page A. This process is known as copy-on-write (CoW). 104- What happens if there is no free frame when a page fault occurs? Answer : OS has to replace a frame to bring in the demanded page. 105- What is a “modify (dirty) bit?” What is the difference between the “dirty” bit and a valid bit? Answer : The valid shows whether the content of the page table is valid or not. The dirty bit shows whether the frame’s content has been changed. If the dirty bit is zero, writing back the frame into the disk is unnecessary. 106- What are “frame allocation” and “page replacement” algorithms? Answer : Frame allocation determines which physical memory frames are assigned to virtual memory pages. In contrast, page replacement determines which virtual memory pages are moved from physical memory to make room for new pages. 107- Suppose that we have the following sequence of references to virtual pages. Each number in this sequence of 21 references shows the page number that the CPU has referred to . 1, 4, 1, 6, 1,1,1,1, 6, 1,1,1,1, 6, 1,1,1,1, 6, 1,1 Using FIFO, how many page faults occur if a) we only have one frame in our main memory? B) we have two frames in the memory? C) if we have three frames? D) if we have four frames in the memory? Answer : If the main memory is only one frame, then a page fault occurs each time the sequence wants to access a new page. For example, if the sequence has four consecutive 1’s, then only the first reference to page 1 would cause a fault, and the other three references to page 1 are hits. Hence, in the above sequence, 11 page-faults occur if we only have one frame. If we have two frames in the memory, then four page-faults occur. If we have three frames, then three faults occur, and with four frames, we will have three page-faults. 30 108- Suppose that we have the following string of references: 7,0,1,2,0,3,0,4,2,3,0,3,0,3,2,1,2,0,1,7,0,1. Further, assume that we only have three frames in the main memory. We want to use a FIFO strategy for page replacement. Fill out the frames in the image below with the appropriate page number. Answer: 109- What is Belady’s optimal page replacement method? Answer : It considers that it knows the future and replaces the page that will not be used shortly. 110- For the following string of references, fill out the image with appropriate page numbers based on Belady’s Optimal replacement method: 7,0,1,2,0,3,0,4,2,3,0,3,0,3,2,1,2,0,1,7,0,1. 31 Answer: So, in replacing pages, we look at the future string, and if a page is referred to shortly, we won’t replace it. When page 0 was to be brought in, we didn’t replace page 2, which was the oldest, and we replaced page 4 because we knew that we would shortly refer to page 2. 111- For the following string of references, fill out the image with appropriate page numbers based on LRU (least recently used) replacement method: 7,0,1,2,0,3,0,4,2,3,0,3,0,3,2,1,2,0,1,7,0,1. Answer : 112- What are the two main methods for implementing LRU? Answer : 1) Use a counter next to each frame. Every time that frame is referenced, the counter is incremented. The frame with the smallest counter value is replaced when replacing a frame. After each frame replacement, all counters are reset 32 to zero. 2) We can use a stack. When a page enters the main memory, the page number will be on top of the stack. Every time a page is referenced, its number goes to the top of the stack. When we want to replace a frame, the one at the bottom of the stack is replaced. 113- Suppose we are using a stack to implement the LRU replacement method. Consider the string of references shown below. Suppose that we know the content of the stack after point a. What will be the content of the stack after point b? Answer : 114- How is the “second chance” or the “clock” replacement method implemented? Answer : A reference bit (W) is assigned to each frame. Every time that a frame is referenced, its W bit is set to 1. When a frame is replaced, all W bits are reset to zero. The FIFO strategy is implemented. When a page fault occurs, the frames are tested based on FIFO. If the frame has a zero W, then it is replaced. If the frame has one W, then it is given a second chance, and its W is reset to zero. Then the next frame based on FIFO is checked, and so on. 33 115- Suppose that the main memory consists of 4 frames. The following sequence of frames has been referenced: 0,1,2,3,2,1,0,3,2,3. A page fault occurs at the end of this sequence, and one of the frames must be replaced using the “clock” strategy. Which frame is replaced ? Answer : Frame 1 should be replaced. 116- Suppose the following image shows the circular page queue of pages in a FIFO page- replacement mechanism combined with a reference bit. FIFO is now looking at the “next victim.” Which frame will be replaced in this list? What will the list of reference bits look like before the page replacement? Answer: 34 117- What is the “enhanced second-chance” replacement method? Answer : it uses two bits for each frame, a dirty-bit and a reference bit. “00” means that the page is not referenced since the last page-fault, and is not modified. Such a frame has the highest priority for replacement. “10” shows that the frame is referred to but has not been changed. This page has the second-highest replacement priority since it does not need a write-back. “01” indicates that the page is not referenced but modified. This page has the second-lowest priority for removal since we need to write it back into the disk. “11” means that the page has been referenced and has been modified. This page has the lowest priority for replacement. Based on FIFO, frames are tested. If the pair of bits are 00, then the page is replaced. Otherwise, the reference bit of the page is set to zero, and the next frame is tested. A second round is performed if no frame is found in the first round. 118- What is LFU strategy for page replacement ? Answer : Least frequently used page is replaced. Each page has a counter, and every time it is referenced, its counter is incremented. The page with the lowest number of references is replaced. The goal is to replace a page that is not very useful and is referred to not very often. The shortcoming is that a page that is just brought in may be replaced. 119- What is a page buffering algorithm ? Answer : The system keeps a pool of free frames. When a page fault occurs, a victim frame is chosen as before . However, the desired page is read into a free frame from the pool before the victim is written out. This procedure allows the process to restart as soon as 35 possible without waiting for the victim page to be written out. When the victim is later written out, its frame is added to the free-frame pool. 120- Let us assume we are using “proportional allocation” for two processes. We have 62 frames available. One of the processes has 10 pages, and the other 127 pages. How many frames are allocated to each one? Answer : 121- What is thrashing ? Answer : A page fault would occur if a process uses all of its allocated memory space and needs another page. An active page of this process has to be replaced, which causes another page fault. Hence, each page fault replaces a frame that is being used and causes another page fault. Continuous page faults severely reduce performance. This situation is known as “thrashing.” 122- What is the relationship between locality and thrashing? Answer : If the overall locality of all active processes is larger than the physical memory, then thrashing occurs. This situation means that active processes need to refer to a more extensive space than the main memory. Hence, one active frame has to be replaced by a new page, and this loop causes threshing. 123- What is the difference between local and global replacements? Answer : In the local replacement strategy, each process selects only from its set of allocated frames. Hence, this method would result in a consistent per- process performance but could result in underutilized memory. In the global replacement, the system selects a replacement frame from the set of all frames; one process can take a frame from another. This method’s execution time can vary greatly because information about all processes should be considered. But the overall throughput is better than local replacement, which is currently the common method. 36 124- What is the “reclaiming pages” approach in the global page replacement strategy? Answer : Reclaiming pages is the process of freeing up memory pages that are no longer being used by a program or process to make that memory available for other programs or processes. ( When a program or process requests memory, the operating system allocates memory pages to that program or process. However, as the program or process runs, it may no longer need all the memory pages allocated to it. For example, if a program finishes using a particular data structure, the memory pages allocated to that data structure can be reclaimed and made available for other programs. The operating system typically keeps track of which each program or process is using memory pages. When a program or process no longer needs a particular page, the operating system can mark it as free and add it to a pool of available memory pages. These free pages can then be allocated to other programs or processes that need them.